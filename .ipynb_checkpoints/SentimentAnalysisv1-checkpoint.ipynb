{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re ,nltk\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visualize(tweet,Name,Class):\n",
    "    Plot=sns.distplot(Class,kde=False,bins=3,rug=False,color=\"#07438C\")\n",
    "    Plot.set(xlabel=\"Negative          Neutral            Positive\",\n",
    "             ylabel=\"No of tweets\",\n",
    "             title=\"tweets of {} \".format(Name)\n",
    "    )\n",
    "    Plot.plot()\n",
    "    \n",
    "    StopWords=set(STOPWORDS)\n",
    "    all_words = ' '.join([text for text in Xtrain_Obama])\n",
    "    wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean(Tweets):\n",
    "    from nltk.tokenize import WordPunctTokenizer\n",
    "    pattern=re.compile(r'(https|http):?//[a-zA-Z0-9./]+|<.*?>|@\\w+|RT @\\w+')\n",
    "    Stopwords={sw for sw in nltk.corpus.stopwords.words('english')}\n",
    "    processed=[]\n",
    "    \n",
    "    for tweet in Tweets:\n",
    "        # remove html tags,URL links,twitter handles\n",
    "        tweet=pattern.sub('',tweet)\n",
    "        \n",
    "        \n",
    "        #remove all special characters (except #)\n",
    "        tweet=re.sub(r'[^a-zA-Z0-9# ]',\" \",tweet).lower()\n",
    "        \n",
    "        \n",
    "        # tokenize to remove extra space and remove stopwords\n",
    "        tweet=tweet.split()\n",
    "        tweet=' '.join(([w for w in tweet if not w in Stopwords]))\n",
    "        \n",
    "        #Convert each word to its root word\n",
    "        Root=nltk.stem.PorterStemmer()\n",
    "        Tweet_root=[Root.stem(w) for w in tweet.split()]\n",
    "        tweet=tweet=str(' '.join(Tweet_root))\n",
    "        \n",
    "        processed.append(tweet)\n",
    "        \n",
    "        \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parameter_Tuning(parameters,model,X,y):\n",
    "    gs_clf=GridSearchCV(model,parameters,cv=10,iid=False,n_jobs=-1)\n",
    "    GS_clf=gs_clf.fit(X,y)\n",
    "    print(\"Best Score for the model--->{0}\".format(GS_clf.best_score_))\n",
    "    print(\"Best Parameters are...\")\n",
    "    print(GS_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Obama_tweets=df_Obama_tweets=pd.read_excel('trainingObamaRomneytweets.xlsx',sheet_name='Obama')\n",
    "df_Romney_tweets=pd.read_excel('trainingObamaRomneytweets.xlsx',sheet_name='Romney')\n",
    "\n",
    "# retains first 4 columns\n",
    "df_Obama_tweets=df_Obama_tweets[1:].dropna(axis=1,how='all')\n",
    "df_Romney_tweets=df_Romney_tweets[1:].dropna(axis=1,how='all')\n",
    "\n",
    "\n",
    "\n",
    "#rename the colums\n",
    "df_Obama_tweets.columns=['Date','Time','Tweets','Class']\n",
    "df_Romney_tweets.columns=['Date','Time','Tweets','Class']\n",
    "df_Obama_tweets.index=range(1,len(df_Obama_tweets)+1)\n",
    "df_Romney_tweets.index=range(1,len(df_Romney_tweets)+1)\n",
    "\n",
    "\n",
    "#drop mixed and !!! class for now(we may consider it later)\n",
    "df_Romney_tweets=df_Romney_tweets[(df_Romney_tweets['Class'].isin((0,1,-1)))]\n",
    "df_Obama_tweets=df_Obama_tweets[(df_Obama_tweets['Class'].isin((0,1,-1)))]\n",
    "\n",
    "#drop empty tweet rows\n",
    "df_Obama_tweets.dropna(subset=['Tweets'],inplace=True)\n",
    "df_Romney_tweets.dropna(subset=['Tweets'],inplace=True)\n",
    "\n",
    "#shuffle the dataframe to avoid bias\n",
    "df_Obama_tweets=shuffle(df_Obama_tweets).reset_index(drop=True)\n",
    "df_Romney_tweets=shuffle(df_Romney_tweets).reset_index(drop=True)\n",
    "\n",
    "#raw tweet and class\n",
    "Obama_tweet=df_Obama_tweets['Tweets'].tolist()\n",
    "Obama_class=df_Obama_tweets['Class'].tolist()\n",
    "\n",
    "Romney_tweet=df_Romney_tweets['Tweets'].tolist()\n",
    "Romney_class=df_Romney_tweets['Class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the tweets\n",
    "Xtrain_Obama=Clean(Obama_tweet)\n",
    "Xtrain_Romney=Clean(Romney_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomail NB...\n",
    "\n",
    "#Vectorize the tweet and initialize the classifiers\n",
    "tweet_clf=Pipeline([\n",
    "    ('count_vect',CountVectorizer(max_df=.7)),\n",
    "    ('vect_tfidf',TfidfTransformer()),\n",
    "    ('clf',MultinomialNB()),\n",
    "])\n",
    "\n",
    "#tuning the parameters\n",
    "parameters={\n",
    "    'count_vect__ngram_range':[(1,1),(1,2)],\n",
    "    'count_vect__max_df':(.5,.6,.8,.9),\n",
    "    'vect_tfidf__use_idf':(True,False),\n",
    "    'clf__alpha':(1e-2,1e-3)\n",
    "}\n",
    "\n",
    "Parameter_Tuning(parameters,tweet_clf,Xtrain_Obama,Obama_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVM\n",
    "tweet_clf=Pipeline([\n",
    "    ('count_vect',CountVectorizer(max_df=.7)),\n",
    "    ('vect_tfidf',TfidfTransformer()),\n",
    "    ('clf',LinearSVC(loss='hinge', penalty='l2', random_state=42,\n",
    "                          max_iter=5)),\n",
    "])\n",
    "\n",
    "\n",
    "#tuning the parameters\n",
    "parameters={\n",
    "    'count_vect__ngram_range':[(1,1),(1,2)],\n",
    "    'count_vect__max_df':(.5,.6,.8,.9),\n",
    "    'vect_tfidf__use_idf':(True,False),\n",
    "    'clf__C':(1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3)\n",
    "}\n",
    "\n",
    "Parameter_Tuning(parameters,tweet_clf,Xtrain_Obama,Obama_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "tweet_clf=Pipeline([\n",
    "    ('count_vect',CountVectorizer(max_df=.7)),\n",
    "    ('vect_tfidf',TfidfTransformer()),\n",
    "    ('clf',LogisticRegression(random_state=0)),\n",
    "])\n",
    "\n",
    "\n",
    "#tuning the parameters\n",
    "parameters={\n",
    "    'count_vect__ngram_range':[(1,1),(1,2)],\n",
    "    'count_vect__max_df':(.5,.6,.8,.9),\n",
    "    'vect_tfidf__use_idf':(True,False),\n",
    "    'clf__C':(1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3),\n",
    "    'clf__penalty': ['l2']\n",
    "}\n",
    "\n",
    "Parameter_Tuning(parameters,tweet_clf,Xtrain_Obama,Obama_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysing Hashtags\n",
    "def hashtag(tweets):\n",
    "    hashtag=[]\n",
    "    for tweet in tweets:\n",
    "        ht=re.findall(r'#(\\w+)',tweet)\n",
    "        if ht: hashtag.append(ht)\n",
    "    return hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_Romney=Clean(positive)\n",
    "HT=sum(hashtag(Xtrain_Romney),[])\n",
    "\n",
    "a = nltk.FreqDist(HT)\n",
    "d = pd.DataFrame({'Hashtag': list(a.keys()),\n",
    "                  'Count': list(a.values())})\n",
    "# selecting top 10 most frequent hashtags     \n",
    "d = d.nlargest(columns=\"Count\", n = 10) \n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\")\n",
    "ax.set(ylabel = 'Count')\n",
    "plt.show()\n",
    "\n",
    "N= df_Obama_tweets.loc[df_Obama_tweets['Class']==-1]['Tweets'].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
