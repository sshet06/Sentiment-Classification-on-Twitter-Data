{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re ,nltk\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(Tweets):\n",
    "    processed=[]\n",
    "    StopWords={sw for sw in nltk.corpus.stopwords.words('english')} #nltk.corpus.stopwords.words('english')\n",
    "    s={'\\'s','i\\'d','he\\'s'}\n",
    "    StopWords=StopWords|s\n",
    "    \n",
    "    pattern=re.compile(r'https?[^ ]+|@\\w+|[^a-zA-Z#\\' ]') #remove username and hyperlinks\n",
    "    for tweet in Tweets:\n",
    "        if len(tweet)==0:continue\n",
    "        tweet=re.sub(r'<.*?>','',tweet) #remove html tags\n",
    "        tweet=pattern.sub('',tweet).lower().split()\n",
    "        tweet=' '.join([w for w in tweet if not w in StopWords])\n",
    "        Root=nltk.stem.PorterStemmer()\n",
    "        RootWords=[Root.stem(w) for w in tweet.split()]\n",
    "        tweet=str(' '.join(RootWords))\n",
    "        tweet=tweet.replace(\"'\",\"\").replace(\"\\\"\",\"\").replace(\"#\",\"\")\n",
    "        processed.append(tweet)\n",
    "    return processed   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Obama_tweets=df_Obama_tweets=pd.read_excel('trainingObamaRomneytweets.xlsx',sheet_name='Obama')\n",
    "df_Romney_tweets=pd.read_excel('trainingObamaRomneytweets.xlsx',sheet_name='Romney')\n",
    "\n",
    "# retains first 4 columns\n",
    "df_Obama_tweets=df_Obama_tweets[1:].dropna(axis=1,how='all')\n",
    "df_Romney_tweets=df_Romney_tweets[1:].dropna(axis=1,how='all')\n",
    "\n",
    "#rename the colums\n",
    "df_Obama_tweets.columns=['Date','Time','Tweets','Class']\n",
    "df_Romney_tweets.columns=['Date','Time','Tweets','Class']\n",
    "df_Obama_tweets.index=range(1,len(df_Obama_tweets)+1)\n",
    "df_Romney_tweets.index=range(1,len(df_Romney_tweets)+1)\n",
    "\n",
    "#drop mixed and !!! class for now(we may consider it later)\n",
    "df_Romney_tweets=df_Romney_tweets[(df_Romney_tweets['Class'].isin((0,1,-1)))]\n",
    "df_Obama_tweets=df_Obama_tweets[(df_Obama_tweets['Class'].isin((0,1,-1)))]\n",
    "\n",
    "#drop empty tweet rows\n",
    "df_Obama_tweets.dropna(subset=['Tweets'],inplace=True)\n",
    "df_Romney_tweets.dropna(subset=['Tweets'],inplace=True)\n",
    "\n",
    "#shuffle the dataframe to avoid bias\n",
    "df_Obama_tweets=shuffle(df_Obama_tweets).reset_index(drop=True)\n",
    "df_Romney_tweets=shuffle(df_Romney_tweets).reset_index(drop=True)\n",
    "\n",
    "#raw tweet and class\n",
    "Obama_tweet=df_Obama_tweets['Tweets'].tolist()\n",
    "Obama_class=df_Obama_tweets['Class'].tolist()\n",
    "\n",
    "Romney_tweet=df_Romney_tweets['Tweets'].tolist()\n",
    "Romney_class=df_Romney_tweets['Class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the tweets\n",
    "Xtrain_Obama=Preprocessing(Obama_tweet)\n",
    "Xtrain_Romney=Preprocessing(Romney_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parameter_Tuning(parameters,model,X,y):\n",
    "    gs_clf=GridSearchCV(model,parameters,cv=10,iid=False,n_jobs=-1)\n",
    "    GS_clf=gs_clf.fit(X,y)\n",
    "    print(\"Best Score for the model--->{0}\".format(GS_clf.best_score_))\n",
    "    print(\"Best Parameters are...\")\n",
    "    print(GS_clf.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for the model--->0.577881355178453\n",
      "Best Parameters are...\n",
      "{'clf__alpha': 0.01, 'count_vect__max_df': 0.5, 'count_vect__ngram_range': (1, 2), 'vect_tfidf__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "# Multinomail NB...\n",
    "\n",
    "#Vectorize the tweet and initialize the classifiers\n",
    "tweet_clf=Pipeline([\n",
    "    ('count_vect',CountVectorizer(max_df=.7)),\n",
    "    ('vect_tfidf',TfidfTransformer()),\n",
    "    ('clf',MultinomialNB()),\n",
    "])\n",
    "\n",
    "#tuning the parameters\n",
    "parameters={\n",
    "    'count_vect__ngram_range':[(1,1),(1,2)],\n",
    "    'count_vect__max_df':(.5,.6,.8,.9),\n",
    "    'vect_tfidf__use_idf':(True,False),\n",
    "    'clf__alpha':(1e-2,1e-3)\n",
    "}\n",
    "\n",
    "Parameter_Tuning(parameters,tweet_clf,Xtrain_Obama,Obama_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for the model--->0.6021825802053665\n",
      "Best Parameters are...\n",
      "{'count_vect__max_df': 0.5, 'clf__C': 1.0, 'count_vect__ngram_range': (1, 2), 'vect_tfidf__use_idf': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shet/.local/lib/python3.5/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Linear SVM\n",
    "tweet_clf=Pipeline([\n",
    "    ('count_vect',CountVectorizer(max_df=.7)),\n",
    "    ('vect_tfidf',TfidfTransformer()),\n",
    "    ('clf',LinearSVC(loss='hinge', penalty='l2', random_state=42,\n",
    "                          max_iter=5)),\n",
    "])\n",
    "\n",
    "\n",
    "#tuning the parameters\n",
    "parameters={\n",
    "    'count_vect__ngram_range':[(1,1),(1,2)],\n",
    "    'count_vect__max_df':(.5,.6,.8,.9),\n",
    "    'vect_tfidf__use_idf':(True,False),\n",
    "    'clf__C':(1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3)\n",
    "}\n",
    "\n",
    "Parameter_Tuning(parameters,tweet_clf,Xtrain_Obama,Obama_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "tweet_clf=Pipeline([\n",
    "    ('count_vect',CountVectorizer(max_df=.7)),\n",
    "    ('vect_tfidf',TfidfTransformer()),\n",
    "    ('clf',LinearSVC(loss='hinge', penalty='l2', random_state=42,\n",
    "                          max_iter=5)),\n",
    "])\n",
    "\n",
    "\n",
    "#tuning the parameters\n",
    "parameters={\n",
    "    'count_vect__ngram_range':[(1,1),(1,2)],\n",
    "    'count_vect__max_df':(.5,.6,.8,.9),\n",
    "    'vect_tfidf__use_idf':(True,False),\n",
    "    'clf__C':(1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3)\n",
    "}\n",
    "\n",
    "Parameter_Tuning(parameters,tweet_clf,Xtrain_Obama,Obama_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
